{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB , GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import konlpy\n",
    "\n",
    "#import elice_challenge as ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_out_data = open('./data/test.output')\n",
    "#test_out_data = test_out_data.read()\n",
    "#3test_out_data = test_out_data.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = json.load(open('./data/train_data.json'))\n",
    "\n",
    "test_data = json.load(open('./data/test.input.json'))\n",
    "\n",
    "with open('./data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out_data = test_out.splitlines()\n",
    "\n",
    "grading_data = json.load(open('./data/grading.input.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일이 제대로 읽혔는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76500\n",
      "4500\n",
      "4500\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(len(test_out_data))\n",
    "print(len(grading_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['연합뉴스', '뉴시스', 'MBN', '동아일보', '채널A', '오마이뉴스', 'YTN', 'JTBC', '동아일보', '파이낸셜뉴스']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)[['text','writing']]\n",
    "test_df = pd.DataFrame(test_data)[['text']]\n",
    "test_df['writing'] = test_out_data\n",
    "grading_df = pd.DataFrame(grading_data)[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[앵커]청와대 민정수석을 지냈던 우병우씨의 소재를 놓고 설왕설래가 한창입니다. 지난...</td>\n",
       "      <td>JTBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&lt;언론사명&gt;]새누리당 원내대표 경선을 하루 앞둔 2일 청와대는 사실상 ‘불개입’ ...</td>\n",
       "      <td>서울신문</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>= 박근혜 대통령이 7일 오후 서울 은평구 한국여성정책연구원에서 열린 2016년 ...</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이재오 의원. 사진=이재오 의원 페이스북 캡처[&lt;언론사명&gt; ] 새누리당을 탈당한 이...</td>\n",
       "      <td>아시아경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>]곽상도(사진)새누리당 대구 중남구 예비후보는 24일 보도자료를 통해 \"새누리당이 ...</td>\n",
       "      <td>헤럴드경제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text writing\n",
       "0  [앵커]청와대 민정수석을 지냈던 우병우씨의 소재를 놓고 설왕설래가 한창입니다. 지난...    JTBC\n",
       "1  [<언론사명>]새누리당 원내대표 경선을 하루 앞둔 2일 청와대는 사실상 ‘불개입’ ...    서울신문\n",
       "2   = 박근혜 대통령이 7일 오후 서울 은평구 한국여성정책연구원에서 열린 2016년 ...     뉴시스\n",
       "3  이재오 의원. 사진=이재오 의원 페이스북 캡처[<언론사명> ] 새누리당을 탈당한 이...   아시아경제\n",
       "4  ]곽상도(사진)새누리당 대구 중남구 예비후보는 24일 보도자료를 통해 \"새누리당이 ...   헤럴드경제"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>writing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>日, 위안부지원금 송금완료…'소녀상 압박' 우려(cg)[&lt;언론사명&gt;tv 제공]\\n\\...</td>\n",
       "      <td>연합뉴스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>새누리 \"안보와 안전, 민생이 최우선\" 더민주 \"박 대통령이 먼저 변해야\" 국민의당...</td>\n",
       "      <td>뉴시스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"사실과 다르다\" 국민의당, '김수민 리베이트 의혹' 정면 반박국민의당 김수민/사진...</td>\n",
       "      <td>MBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[&lt;언론사명&gt;]본보-r&amp;r; 총선의 해 여론조사“신인 선택” 31%〉“현역” 24%...</td>\n",
       "      <td>동아일보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김종인 더민주 대표는 자신이 던진 담뱃불이 어떻게 번지는 지, 느긋하게 즐기는 모습...</td>\n",
       "      <td>채널A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text writing\n",
       "0  日, 위안부지원금 송금완료…'소녀상 압박' 우려(cg)[<언론사명>tv 제공]\\n\\...    연합뉴스\n",
       "1  새누리 \"안보와 안전, 민생이 최우선\" 더민주 \"박 대통령이 먼저 변해야\" 국민의당...     뉴시스\n",
       "2  \"사실과 다르다\" 국민의당, '김수민 리베이트 의혹' 정면 반박국민의당 김수민/사진...     MBN\n",
       "3  [<언론사명>]본보-r&r; 총선의 해 여론조사“신인 선택” 31%〉“현역” 24%...    동아일보\n",
       "4  김종인 더민주 대표는 자신이 던진 담뱃불이 어떻게 번지는 지, 느긋하게 즐기는 모습...     채널A"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4당 체제에도 청문회·국감·지방자치 합의 제도적 성과 14대 국회도 3대 정치개혁입...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>눈감은 부산고검장\\n    (부산=&lt;언론사명&gt;)  = 문무일 부산고검장이 11일 부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[앵커] \\n일본 규수 구마모토 지진으로 대규모 사상자가 발생하면서 정부가 신속대응...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>박근혜 대통령이 총선을 하루 앞두고 '새로운 국회론'을 강력히 설파했다. 핵심 민생...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>차은택 구속기소…특검 체제까지 사실상 '8부 능선' 넘어차은택/사진=&lt;언론사명&gt;'비...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  4당 체제에도 청문회·국감·지방자치 합의 제도적 성과 14대 국회도 3대 정치개혁입...\n",
       "1  눈감은 부산고검장\\n    (부산=<언론사명>)  = 문무일 부산고검장이 11일 부...\n",
       "2  [앵커] \\n일본 규수 구마모토 지진으로 대규모 사상자가 발생하면서 정부가 신속대응...\n",
       "3  박근혜 대통령이 총선을 하루 앞두고 '새로운 국회론'을 강력히 설파했다. 핵심 민생...\n",
       "4  차은택 구속기소…특검 체제까지 사실상 '8부 능선' 넘어차은택/사진=<언론사명>'비..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grading_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-875a3f65f11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mp_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('stopwords.txt', 'rb') as f:\n",
    "    p_X = pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('stopwords.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.random.seed(10)\n",
    "# shuffle_indices = np.random.permutation(np.arange(len(train_df)))\n",
    "# X = train_df.text[shuffle_indices[:67000]]\n",
    "# y = train_df.writing[shuffle_indices[:67000]]\n",
    "\n",
    "# test_X = train_df.text[shuffle_indices[67000:]]\n",
    "# test_y = train_df.writing[shuffle_indices[67000:]]\n",
    "\n",
    "X = train_df.text\n",
    "y = train_df.writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stw = ['은/Josa','는/Josa','이/Josa','가/Josa','에서/Josa','의/Josa','을/Josa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stw = ['은/Josa','[/Punctuation',']/Punctuation','(/Punctuation','/Punctuation',\n",
    "       ',/Punctuation','./Punctuation','?/Punctuation','!/Punctuation','!!/Punctuation','\"/Punctuation',\n",
    "      ';/Punctuation',':/Punctuation','//Punctuation','-/Punctuation','~/Punctuation','.../Punctuation',\n",
    "      '에/Josa','는/Josa','이/Josa','가/Josa','를/Josa','께서/Josa','게/Josa','고/Josa','마다/Josa','이라고도/Josa',\n",
    "      '보다는/Josa','로운/Josa','까지야/Josa','했지만/Josa','만/Josa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5869124073e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \"\"\"\n\u001b[0;32m-> 1352\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 839\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 241\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "# 처음엔 이걸로 # vectorize train using Tfid(bag of words)\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), stop_words=stw)\n",
    "\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # vectorize train using Tfid(bag of words)\n",
    "\n",
    "# twitter = Twitter()\n",
    "\n",
    "# def tokenize_pos(doc):\n",
    "#     return ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "# vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2),\n",
    "#                               use_idf=False, smooth_idf=False,\n",
    "#                               vocabulary = reduced_feature_list)\n",
    "\n",
    "# X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # sparse matrix test\n",
    "# import random\n",
    "# import scipy.sparse as sparse\n",
    "# import scipy.io\n",
    "# import numpy as np\n",
    "\n",
    "# def save_sparse_matrix(filename, x):\n",
    "#     x_coo = x.tocoo()\n",
    "#     row = x_coo.row\n",
    "#     col = x_coo.col\n",
    "#     data = x_coo.data\n",
    "#     shape = x_coo.shape\n",
    "#     np.savez(filename, row=row, col=col, data=data, shape=shape)\n",
    "\n",
    "# def load_sparse_matrix(filename):\n",
    "#     y = np.load(filename)\n",
    "#     z = sparse.coo_matrix((y['data'], (y['row'], y['col'])), shape=y['shape'])\n",
    "#     return z\n",
    "\n",
    "# N=20000\n",
    "# x = sparse.lil_matrix( (N,N) )\n",
    "# for i in xrange(N):\n",
    "#     x[random.randint(0,N-1),random.randint(0,N-1)]=random.randint(1,100)\n",
    "\n",
    "# save_sparse_matrix('/tmp/my_array',x)\n",
    "# load_sparse_matrix('/tmp/my_array.npz').tolil()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fitting train data with classifier\n",
    "\n",
    "#model = SGDClassifier(alpha=1.9e-6, n_iter=19).fit(X, y)\n",
    "model = LogisticRegression(C=10200).fit(X,y)\n",
    "#model = xgboost.XGBClassifier().fit(X,y)\n",
    "#model = MultinomialNB(alpha=5).fit(X,y)\n",
    "#model = ExtraTreesClassifier(n_estimators=10).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "Name: pos, dtype: bool"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list.pos.str.contains('Josa')==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941228, 1)"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = vectorizer.get_feature_names()\n",
    "pos_list = pd.DataFrame(feature_list,columns=['pos'])\n",
    "reduced_feature_list = pos_list[pos_list.pos.str.contains('Josa')==False]\n",
    "\n",
    "reduced_feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict test data\n",
    "\n",
    "def testX_to_vec(X):\n",
    "    feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "    test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list)\n",
    "    X_test = test_vectorizer.fit_transform(X)\n",
    "    \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # reduced feature) predict test data\n",
    "\n",
    "# def testX_to_vec(X):\n",
    "#     feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "#     test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = reduced_feature_list)\n",
    "#     X_test = test_vectorizer.fit_transform(X)\n",
    "    \n",
    "#     return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X = test_df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic 10200, true, true, stw 2\n",
    "rank_class = predict_rank(test_X)\n",
    "mrr(rank_class, test_out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "TfidfVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-24df31c129e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#test to vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestX_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-cf9d0cfbc5d9>\u001b[0m in \u001b[0;36mtestX_to_vec\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtestX_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfeature_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m         \u001b[0;34m\"\"\"Array mapping from feature integer indices to feature name\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocabulary_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# FIXME NotFittedError_ --> NotFittedError in 0.19\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_NotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "#test to vec\n",
    "test_X = testX_to_vec(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grid search logistic C 5\n",
    "\n",
    "alpha=[100, 500, 1000, 5000, 9800, 20000, 1000000, 10000000]\n",
    "for i,val in enumerate(alpha):\n",
    "    model = LogisticRegression(C=val).fit(X,y)\n",
    "    rank_class = predict_rank(test_X)\n",
    "    print(val, mrr(rank_class, test_df.writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.900222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       JTBC       0.97      0.88      0.92       139\n",
      "     KBS 뉴스       0.96      0.92      0.94       372\n",
      "        MBN       0.96      0.95      0.96       437\n",
      "       TV조선       0.99      0.91      0.95        90\n",
      "        YTN       0.89      0.90      0.89       232\n",
      "       경향신문       0.81      0.62      0.70       100\n",
      "       국민일보       0.74      0.82      0.78       336\n",
      "       노컷뉴스       0.97      0.89      0.93        35\n",
      "        뉴시스       0.91      0.98      0.94       661\n",
      "       동아일보       0.88      0.88      0.88       290\n",
      "       매일경제       0.73      0.68      0.70       186\n",
      "       서울신문       0.79      0.85      0.82       253\n",
      "      아시아경제       0.92      0.94      0.93        48\n",
      "       연합뉴스       1.00      0.99      0.99       487\n",
      "     연합뉴스TV       0.94      0.96      0.95       191\n",
      "      오마이뉴스       0.98      0.98      0.98       121\n",
      "        채널A       1.00      0.98      0.99       122\n",
      "     파이낸셜뉴스       0.85      0.85      0.85       243\n",
      "      헤럴드경제       0.89      0.71      0.79       157\n",
      "\n",
      "avg / total       0.90      0.90      0.90      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reduced \n",
    "test_pred = model.predict(test_X)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(test_df.writing, test_pred))\n",
    "\n",
    "\n",
    "print(classification_report(test_df.writing, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       JTBC       1.00      0.68      0.81       139\n",
      "     KBS 뉴스       0.89      0.92      0.90       372\n",
      "        MBN       0.95      0.92      0.94       437\n",
      "       TV조선       0.99      0.83      0.90        90\n",
      "        YTN       0.75      0.92      0.83       232\n",
      "       경향신문       0.59      0.60      0.59       100\n",
      "       국민일보       0.51      0.86      0.64       336\n",
      "       노컷뉴스       1.00      0.71      0.83        35\n",
      "        뉴시스       0.88      0.95      0.92       661\n",
      "       동아일보       0.94      0.65      0.77       290\n",
      "       매일경제       0.71      0.46      0.56       186\n",
      "       서울신문       0.99      0.31      0.47       253\n",
      "      아시아경제       0.94      0.33      0.49        48\n",
      "       연합뉴스       1.00      0.69      0.82       487\n",
      "     연합뉴스TV       0.93      0.93      0.93       191\n",
      "      오마이뉴스       1.00      0.63      0.77       121\n",
      "        채널A       0.91      0.99      0.95       122\n",
      "     파이낸셜뉴스       0.51      0.92      0.65       243\n",
      "      헤럴드경제       0.52      0.76      0.62       157\n",
      "\n",
      "avg / total       0.84      0.79      0.79      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic C=10\n",
    "test_pred = model.predict(test_X)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(test_df.writing, test_pred))\n",
    "\n",
    "\n",
    "print(classification_report(test_df.writing, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.600222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       JTBC       0.88      0.58      0.70       139\n",
      "     KBS 뉴스       0.66      0.59      0.62       372\n",
      "        MBN       0.69      0.73      0.71       437\n",
      "       TV조선       1.00      0.14      0.25        90\n",
      "        YTN       0.70      0.79      0.74       232\n",
      "       경향신문       0.75      0.03      0.06       100\n",
      "       국민일보       0.41      0.46      0.43       336\n",
      "       노컷뉴스       1.00      0.17      0.29        35\n",
      "        뉴시스       0.62      0.81      0.70       661\n",
      "       동아일보       0.50      0.76      0.61       290\n",
      "       매일경제       0.45      0.27      0.34       186\n",
      "       서울신문       0.51      0.38      0.44       253\n",
      "      아시아경제       0.00      0.00      0.00        48\n",
      "       연합뉴스       0.51      0.82      0.62       487\n",
      "     연합뉴스TV       0.75      0.70      0.72       191\n",
      "      오마이뉴스       0.86      0.66      0.75       121\n",
      "        채널A       0.92      0.54      0.68       122\n",
      "     파이낸셜뉴스       0.59      0.41      0.48       243\n",
      "      헤럴드경제       0.84      0.29      0.43       157\n",
      "\n",
      "avg / total       0.63      0.60      0.58      4500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoo/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# NB\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(test_df.writing, test_pred))\n",
    "# 0.8111\n",
    "\n",
    "print(classification_report(test_df.writing, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582888888889\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       JTBC       0.64      0.55      0.59       139\n",
      "     KBS 뉴스       0.65      0.84      0.73       372\n",
      "        MBN       0.67      0.73      0.70       437\n",
      "       TV조선       0.71      0.49      0.58        90\n",
      "        YTN       0.72      0.67      0.69       232\n",
      "       경향신문       0.21      0.08      0.12       100\n",
      "       국민일보       0.33      0.36      0.34       336\n",
      "       노컷뉴스       1.00      0.63      0.77        35\n",
      "        뉴시스       0.45      0.88      0.60       661\n",
      "       동아일보       0.50      0.56      0.53       290\n",
      "       매일경제       0.38      0.06      0.10       186\n",
      "       서울신문       0.49      0.36      0.41       253\n",
      "      아시아경제       0.89      0.17      0.28        48\n",
      "       연합뉴스       0.79      0.68      0.73       487\n",
      "     연합뉴스TV       0.84      0.65      0.74       191\n",
      "      오마이뉴스       1.00      0.64      0.78       121\n",
      "        채널A       0.84      0.70      0.76       122\n",
      "     파이낸셜뉴스       0.74      0.26      0.38       243\n",
      "      헤럴드경제       0.68      0.20      0.31       157\n",
      "\n",
      "avg / total       0.61      0.58      0.56      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# forest\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(test_df.writing, test_pred))\n",
    "# 0.8111\n",
    "\n",
    "print(classification_report(test_df.writing, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811111111111\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       JTBC       1.00      0.71      0.83       139\n",
      "     KBS 뉴스       0.92      0.90      0.91       372\n",
      "        MBN       0.95      0.93      0.94       437\n",
      "       TV조선       1.00      0.86      0.92        90\n",
      "        YTN       0.76      0.94      0.84       232\n",
      "       경향신문       0.66      0.60      0.63       100\n",
      "       국민일보       0.54      0.85      0.66       336\n",
      "       노컷뉴스       1.00      0.74      0.85        35\n",
      "        뉴시스       0.88      0.95      0.92       661\n",
      "       동아일보       0.92      0.72      0.81       290\n",
      "       매일경제       0.71      0.55      0.62       186\n",
      "       서울신문       0.95      0.38      0.54       253\n",
      "      아시아경제       1.00      0.35      0.52        48\n",
      "       연합뉴스       1.00      0.75      0.86       487\n",
      "     연합뉴스TV       0.93      0.94      0.93       191\n",
      "      오마이뉴스       1.00      0.64      0.78       121\n",
      "        채널A       0.95      0.99      0.97       122\n",
      "     파이낸셜뉴스       0.55      0.92      0.68       243\n",
      "      헤럴드경제       0.56      0.78      0.65       157\n",
      "\n",
      "avg / total       0.85      0.81      0.81      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(test_df.writing, test_pred))\n",
    "# 0.8111\n",
    "\n",
    "print(classification_report(test_df.writing, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "#xgboost\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(accuracy_score(test_df.writing, test_pred))\n",
    "# 0.8111\n",
    "\n",
    "print(classification_report(test_df.writing, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_rank(X_test):\n",
    "    \n",
    "    test_prob = model.predict_proba(X_test)\n",
    "\n",
    "    test_class = pd.DataFrame((-test_prob).argsort())\n",
    "    \n",
    "    class_df = pd.DataFrame(model.classes_).reset_index()\n",
    "    \n",
    "    # data frame 생성\n",
    "    for i in range(len(model.classes_)):\n",
    "        class_df.columns = [i, 'rank_'+str(i)]\n",
    "        test_class = pd.merge(test_class, class_df, on=i, how='left')\n",
    "\n",
    "    # rank columns    \n",
    "    rank_columns = ['rank_0',  'rank_1',  'rank_2',  'rank_3',  'rank_4',\n",
    "                    'rank_5',  'rank_6',  'rank_7',  'rank_8',  'rank_9', \n",
    "                    'rank_10', 'rank_11', 'rank_12', 'rank_13', 'rank_14', \n",
    "                    'rank_15', 'rank_16', 'rank_17', 'rank_18']\n",
    "\n",
    "    #dataframe to csv\n",
    "    test_class_csv = test_class[rank_columns].to_csv(header=False, index=False)\n",
    "    test_class_csv = test_class_csv.splitlines()\n",
    "    \n",
    "    return test_class_csv#test_class_csv[0], '...\\n \\n ', test_class_csv[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict rank\n",
    "rank_class = predict_rank(test_X) # test score 0.87846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['연합뉴스,아시아경제,뉴시스,파이낸셜뉴스,JTBC,채널A,오마이뉴스,연합뉴스TV,서울신문,매일경제,동아일보,국민일보,경향신문,YTN,TV조선,MBN,KBS 뉴스,노컷뉴스,헤럴드경제',\n",
       " '뉴시스,연합뉴스,MBN,JTBC,채널A,오마이뉴스,연합뉴스TV,아시아경제,서울신문,매일경제,동아일보,노컷뉴스,국민일보,경향신문,YTN,TV조선,KBS 뉴스,파이낸셜뉴스,헤럴드경제']"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict 결과 확인\n",
    "rank_class[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write csv\n",
    "output_file = 'submission.txt'\n",
    "with open(output_file, 'w') as fp:\n",
    "    for row in rank_class:\n",
    "        fp.write(row)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mrr(rank_class, test_out_data):\n",
    "\n",
    "    pred = []\n",
    "    for i in range(len(rank_class)):\n",
    "        pred.append(rank_class[i].split(','))\n",
    "    \n",
    "    position = np.zeros([len(rank_class),1])\n",
    "    pred = np.array(pred)\n",
    "    test_true = np.array(test_out_data)\n",
    "    \n",
    "    for i in range(len(rank_class)):\n",
    "        position[i] = np.where(pred[i]==test_true[i])[0]+1\n",
    "    \n",
    "    return ((1/position).sum())/len(rank_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86249111074111073"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr(rank_class, test_out_data) #logistic C = 10 featurelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93987501570210552"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr(rank_class, test_out_data) #logistic C = 10000 true true stw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.480534784582\n",
      "0.1 0.650051231219\n",
      "1 0.783010539492\n",
      "15 0.870699469666\n",
      "25 0.87711188102\n",
      "45 0.880247206497\n"
     ]
    }
   ],
   "source": [
    "#grid search logistic C 2\n",
    "\n",
    "alpha=[0.01, 0.1, 1, 15, 25, 45]\n",
    "for i,val in enumerate(alpha):\n",
    "    model = LogisticRegression(C=val).fit(X,y)\n",
    "    rank_class = predict_rank(test_X)\n",
    "    print(val, mrr(rank_class, test_df.writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9900 0.894274588774\n",
      "10100 0.893767222991\n",
      "10200 0.894535876252\n"
     ]
    }
   ],
   "source": [
    "#grid search logistic C 5\n",
    "\n",
    "alpha=[9900, 10100, 10200, 10300]\n",
    "for i,val in enumerate(alpha):\n",
    "    model = LogisticRegression(C=val).fit(X,y)\n",
    "    rank_class = predict_rank(test_X)\n",
    "    print(val, mrr(rank_class, test_df.writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000 0.894079127753\n",
      "12000 0.89368093798\n",
      "13000 0.894096626612\n"
     ]
    }
   ],
   "source": [
    "#grid search logistic C 5\n",
    "\n",
    "alpha=[11000, 12000, 13000]\n",
    "for i,val in enumerate(alpha):\n",
    "    model = LogisticRegression(C=val).fit(X,y)\n",
    "    rank_class = predict_rank(test_X)\n",
    "    print(val, mrr(rank_class, test_df.writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 0.893717458649\n",
      "40000 0.893469522018\n",
      "60000 0.892794708033\n"
     ]
    }
   ],
   "source": [
    "#grid search logistic C 4\n",
    "\n",
    "alpha=[20000, 40000, 60000]\n",
    "for i,val in enumerate(alpha):\n",
    "    model = LogisticRegression(C=val).fit(X,y)\n",
    "    rank_class = predict_rank(test_X)\n",
    "    print(val, mrr(rank_class, test_df.writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 0.892520188544\n",
      "10000 0.894128997945\n",
      "100000 0.893223218938\n"
     ]
    }
   ],
   "source": [
    "#grid search logistic C 3\n",
    "\n",
    "alpha=[2000, 10000, 100000]\n",
    "for i,val in enumerate(alpha):\n",
    "    model = LogisticRegression(C=val).fit(X,y)\n",
    "    rank_class = predict_rank(test_X)\n",
    "    print(val, mrr(rank_class, test_df.writing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1000 -> 0.891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 0.881877988061\n",
      "65 0.882586373503\n",
      "75 0.884111527362\n",
      "85 0.884764261048\n",
      "95 0.885041231608\n",
      "105 0.885410111802\n"
     ]
    }
   ],
   "source": [
    "#grid search logistic C 2\n",
    "\n",
    "alpha=[55, 65, 75, 85, 95, 105]\n",
    "for i,val in enumerate(alpha):\n",
    "    model = LogisticRegression(C=val).fit(X,y)\n",
    "    rank_class = predict_rank(test_X)\n",
    "    print(val, mrr(rank_class, test_df.writing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict grading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    취재진 질문에 답하는 조인근 전 비서관\\n    (서울=<언론사명>)  = 조인근 ...\n",
       "21    [<언론사명>]사진=<언론사명> 캡처 ‘최순실 게이트’의 핵심 증거 중 하나로 꼽히...\n",
       "22    최경환 의원(왼쪽)과 안종범 수석(오른쪽)\\n기재위, 청문회 실시계획서 채택 불발…...\n",
       "23    김 전 차관 오전 10시, 최씨 오후 2시 출석 예정 삼성그룹의 최씨 일가 특혜 지...\n",
       "24    [<언론사명>]김종인 공격 국민의당 되레↓ 쟁점 법안 촉구 땐 13%대 반등 여론조...\n",
       "25     = 정부가 북한의 gps 전파 교란 도발과 관련해 유엔 안전보장이사회와 관련 국제...\n",
       "26    북한이 연일 미국과 한반도 주변 국가간 갈등을 부각하며 미국의 \"쇠퇴\"를 주장하고 ...\n",
       "27    임명장 수여식·공식발표 없는 취임식 강행은 경찰청 출범 25년 만에 ][기사보강: ...\n",
       "28    여론조사 전문기관 리얼미터(대표 이택수)의 2016년 1월 4주차(25~29일) 여...\n",
       "29    총선 주요 공약 강봉균 공동선대위원장이 직접  = 새누리당은 28일 공천자대회와 선...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grading_df['text'][20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#grading to vec\n",
    "X_grading = grading_df['text']\n",
    "X_grading = testX_to_vec(X_grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict rank\n",
    "grading_rank_class = predict_rank(X_grading) # test score 0.87846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'매일경제,뉴시스,연합뉴스,MBN,파이낸셜뉴스,국민일보,오마이뉴스,아시아경제,KBS 뉴스,JTBC,연합뉴스TV,노컷뉴스,채널A,TV조선,YTN,동아일보,헤럴드경제,서울신문,경향신문'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict 결과 확인\n",
    "grading_rank_class[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write csv\n",
    "output_file = 'submission.txt'\n",
    "with open(output_file, 'w') as fp:\n",
    "    for row in grading_rank_class:\n",
    "        fp.write(row)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전에 업로드 된 파일 삭제 중...\n",
      "\n",
      "두 종류의 파일들을 제출해야 합니다.\n",
      " - submission.txt : grading.input.json 에 해당하는 출력값\n",
      " - submission.ipynb 혹은 submission.py : submission.txt를 재현가능한 소스 코드\n",
      "제출할 파일들은 comma (,) 로 나누어 써서 제출할 수 있습니다.\n",
      "제출 예제) submission.ipynb,submission.txt,additional_data.json\n",
      "\n",
      "> submission.txt,submission.ipynb\n",
      "submission.txt 체크 중...\n",
      "submission.txt: 2016000 bytes\n",
      "submission.ipynb 체크 중...\n",
      "submission.ipynb: 5856 bytes\n",
      "업로드 중: submission.txt\n",
      "업로드 중: submission.ipynb\n",
      "업로드가 완료되었습니다.\n",
      "submit() 으로 점수를 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "ec.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "업로드가 완료되면 제출을 시도해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission 데이터 개수 = 9000\n",
      "답안 데이터 개수 = 9000\n",
      "MRR: 0.18645\n",
      "Score: 18 pts.\n",
      "18\n",
      "Score: 18\n"
     ]
    }
   ],
   "source": [
    "ec.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
