{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB , GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "import konlpy\n",
    "\n",
    "#import elice_challenge as ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_data = open('/elice/data/test.output')\n",
    "#test_out_data = test_out_data.read()\n",
    "#3test_out_data = test_out_data.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open('/elice/data/train_data.json'))\n",
    "\n",
    "test_data = json.load(open('/elice/data/test.input.json'))\n",
    "\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out_data = test_out.splitlines()\n",
    "\n",
    "grading_data = json.load(open('/elice/data/grading.input.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일이 제대로 읽혔는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data)[['text','writing']]\n",
    "test_df = pd.DataFrame(test_data)[['text']]\n",
    "test_df['writing'] = test_out_data\n",
    "grading_df = pd.DataFrame(grading_data)[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.text\n",
    "y = train_df.writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음엔 이걸로 # vectorize train using Tfid(bag of words)\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))\n",
    "\n",
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting train data with classifier\n",
    "\n",
    "#model = SGDClassifier(alpha=1.9e-6, n_iter=19).fit(X, y)\n",
    "model = LogisticRegression(C=15800).fit(X,y)\n",
    "#model = xgboost.XGBClassifier().fit(X,y)\n",
    "#model = MultinomialNB(alpha=5).fit(X,y)\n",
    "#model = ExtraTreesClassifier(n_estimators=10).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for predicting test data\n",
    "\n",
    "def testX_to_vec(X):\n",
    "    feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "    test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,3), vocabulary = feature_list)\n",
    "    X_test = test_vectorizer.fit_transform(X)\n",
    "    \n",
    "    return X_test\n",
    "\n",
    "\n",
    "def predict_rank(X_test):\n",
    "    \n",
    "    test_prob = model.predict_proba(X_test)\n",
    "\n",
    "    test_class = pd.DataFrame((-test_prob).argsort())\n",
    "    \n",
    "    class_df = pd.DataFrame(model.classes_).reset_index()\n",
    "    \n",
    "    # data frame 생성\n",
    "    for i in range(len(model.classes_)):\n",
    "        class_df.columns = [i, 'rank_'+str(i)]\n",
    "        test_class = pd.merge(test_class, class_df, on=i, how='left')\n",
    "\n",
    "    # rank columns    \n",
    "    rank_columns = ['rank_0',  'rank_1',  'rank_2',  'rank_3',  'rank_4',\n",
    "                    'rank_5',  'rank_6',  'rank_7',  'rank_8',  'rank_9', \n",
    "                    'rank_10', 'rank_11', 'rank_12', 'rank_13', 'rank_14', \n",
    "                    'rank_15', 'rank_16', 'rank_17', 'rank_18']\n",
    "\n",
    "    #dataframe to csv\n",
    "    test_class_csv = test_class[rank_columns].to_csv(header=False, index=False)\n",
    "    test_class_csv = test_class_csv.splitlines()\n",
    "    \n",
    "    return test_class_csv\n",
    "\n",
    "\n",
    "\n",
    "def mrr(rank_class, test_out_data):\n",
    "\n",
    "    pred = []\n",
    "    for i in range(len(rank_class)):\n",
    "        pred.append(rank_class[i].split(','))\n",
    "    \n",
    "    position = np.zeros([len(rank_class),1])\n",
    "    pred = np.array(pred)\n",
    "    test_true = np.array(test_out_data)\n",
    "    \n",
    "    for i in range(len(rank_class)):\n",
    "        position[i] = np.where(pred[i]==test_true[i])[0]+1\n",
    "    \n",
    "    return ((1/position).sum())/len(rank_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df.text\n",
    "#test to vec\n",
    "test_X = testX_to_vec(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93939857516733172"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_class = predict_rank(test_X)\n",
    "mrr(rank_class, test_out_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict grading_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grading to vec\n",
    "X_grading = grading_df['text']\n",
    "X_grading = testX_to_vec(X_grading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict rank\n",
    "grading_rank_class = predict_rank(X_grading) # test score 0.87846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv\n",
    "output_file = 'submission.txt'\n",
    "with open(output_file, 'w') as fp:\n",
    "    for row in grading_rank_class:\n",
    "        fp.write(row)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import elice_challenge as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이전에 업로드 된 파일 삭제 중...\n",
      "\n",
      "두 종류의 파일들을 제출해야 합니다.\n",
      " - submission.txt : grading.input.json 에 해당하는 출력값\n",
      " - submission.ipynb 혹은 submission.py : submission.txt를 재현가능한 소스 코드\n",
      "제출할 파일들은 comma (,) 로 나누어 써서 제출할 수 있습니다.\n",
      "제출 예제) submission.ipynb,submission.txt,additional_data.json\n",
      "\n",
      "> submission.txt,classify_article.ipynb\n",
      "submission.txt 체크 중...\n",
      "submission.txt: 2016000 bytes\n",
      "classify_article.ipynb 체크 중...\n",
      "classify_article.ipynb: 10212 bytes\n",
      "업로드 중: submission.txt\n",
      "업로드 중: classify_article.ipynb\n",
      "업로드가 완료되었습니다.\n",
      "submit() 으로 점수를 확인할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "ec.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "업로드가 완료되면 제출을 시도해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission 데이터 개수 = 9000\n",
      "답안 데이터 개수 = 9000\n",
      "MRR: 0.94435\n",
      "Score: 94 pts.\n",
      "94\n",
      "Score: 94\n"
     ]
    }
   ],
   "source": [
    "ec.submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
