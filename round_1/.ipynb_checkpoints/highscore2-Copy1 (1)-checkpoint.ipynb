{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB , GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read train data\n",
    "with open('./data/train_data.json') as fp:\n",
    "    json_str = fp.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    \n",
    "# convert to dataframe\n",
    "train_df = pd.DataFrame(json_data)\n",
    "\n",
    "# train data preprocessing\n",
    "train_df['rating_cat'] = train_df['rating'].apply(lambda x: \n",
    "                    'NEG' if 1<= x <=3 \n",
    "                     else \n",
    "                      ('NEU' if 4<=x<=7 \n",
    "                     else 'POS'))\n",
    "\n",
    "# read test data in/out\n",
    "with open('./data/test.input') as fp:\n",
    "    test_in = fp.read()\n",
    "    test_in = test_in.splitlines()\n",
    "\n",
    "with open('./data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize train\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), use_idf=False, smooth_idf=False)\n",
    "\n",
    "\n",
    "y = train_df.rating_cat\n",
    "X = vectorizer.fit_transform(train_df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function 변경\n",
    "#model = SGDClassifier(alpha=1.9e-6, n_iter=19).fit(X, y)\n",
    "model = LogisticRegression(C=30).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = SGDClassifier(loss='modified_huber',alpha=1.9e-6, n_iter=19)\n",
    "model2 = SGDClassifier(loss='modified_huber',alpha=3.9e-6, n_iter=19)\n",
    "model3 = SGDClassifier(loss='modified_huber',alpha=2.9e-6, n_iter=19)\n",
    "model4 = SGDClassifier(loss='modified_huber',alpha=2.9e-6, n_iter=19)\n",
    "model5 = SGDClassifier(loss='modified_huber',alpha=2.9e-6, n_iter=19)\n",
    "model6 = SGDClassifier(loss='modified_huber',alpha=2.9e-6, n_iter=19)\n",
    "\n",
    "#model3 = LinearSVC(C=0.5)#LinearSVC(C=0.5)\n",
    "ensemble = VotingClassifier(estimators=[('svc1', model1), ('svc2', model2), ('svc3', model3)\n",
    "                                    , ('svc4', model4)  , ('svc5', model5), ('svc6', model6) ], \n",
    "                           voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ensemble.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list)\n",
    "X_test = test_vectorizer.fit_transform(test_in[:8400])\n",
    "\n",
    "\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = ensemble.fit(X, y)\n",
    "model = SGDClassifier(alpha=2.9e-6, n_iter=19).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ensemble.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearSVC(C=0.2).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize test_x, predict test_y\n",
    "with open('./data/test.input') as fp:\n",
    "    test_in = fp.read()\n",
    "    test_in = test_in.splitlines()\n",
    "    \n",
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list)\n",
    "X_test = test_vectorizer.fit_transform(test_in[:8400])\n",
    "\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "with open('./data/grading.input') as fp:\n",
    "    sbm_in = fp.read()\n",
    "    sbm_in = sbm_in.splitlines()\n",
    " \n",
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list)\n",
    "sbm_test = test_vectorizer.fit_transform(sbm_in[:8400])\n",
    "\n",
    "sbm_pred = model.predict(sbm_test)\n",
    "\n",
    "output_file = 'submission.txt'#sys.argv[2] # \n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in sbm_pred:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbm_pred = model.predict(sbm_test)\n",
    "output_file = 'submission.txt'#sys.argv[2] # \n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in sbm_pred:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.58      0.55      0.56      1022\n",
      "        NEU       0.51      0.46      0.48      1825\n",
      "        POS       0.84      0.87      0.86      5553\n",
      "\n",
      "avg / total       0.74      0.74      0.74      8400\n",
      "\n",
      "0.744047619048\n",
      "0.743\n",
      "0.76\n",
      "0.715\n",
      "0.755833333333\n"
     ]
    }
   ],
   "source": [
    "# logistic c30\n",
    "with open('./data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.62      0.57      0.60      1022\n",
      "        NEU       0.65      0.40      0.49      1825\n",
      "        POS       0.82      0.94      0.88      5553\n",
      "\n",
      "avg / total       0.76      0.78      0.76      8400\n",
      "\n",
      "0.775833333333\n",
      "0.7745\n",
      "0.7925\n",
      "0.746\n",
      "0.787916666667\n"
     ]
    }
   ],
   "source": [
    "# linear sgd 1.9 5\n",
    "with open('./data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.65      0.52      0.58      1022\n",
      "        NEU       0.69      0.34      0.46      1825\n",
      "        POS       0.80      0.96      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.75      8400\n",
      "\n",
      "0.772142857143\n",
      "0.7815\n",
      "0.78\n",
      "0.736\n",
      "0.787916666667\n"
     ]
    }
   ],
   "source": [
    "# linear sgd 3.9 e\n",
    "with open('./data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.62      0.57      0.59      1022\n",
      "        NEU       0.62      0.41      0.49      1825\n",
      "        POS       0.83      0.93      0.88      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.76      8400\n",
      "\n",
      "0.77369047619\n",
      "0.7765\n",
      "0.781\n",
      "0.745\n",
      "0.789166666667\n"
     ]
    }
   ],
   "source": [
    "# linear svc 1e6 19\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.65      0.54      0.59      1022\n",
      "        NEU       0.61      0.42      0.50      1825\n",
      "        POS       0.82      0.93      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.76      8400\n",
      "\n",
      "0.773214285714\n",
      "0.78\n",
      "0.78\n",
      "0.743\n",
      "0.787083333333\n"
     ]
    }
   ],
   "source": [
    "# linear svc 0.2 \n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.64      0.54      0.59      1022\n",
      "        NEU       0.66      0.38      0.48      1825\n",
      "        POS       0.81      0.95      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.75      8400\n",
      "\n",
      "0.774285714286\n",
      "0.782\n",
      "0.7825\n",
      "0.741\n",
      "0.78875\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (3.9*e-6) #high score # 최대\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.63      0.56      0.59      1022\n",
      "        NEU       0.67      0.39      0.49      1825\n",
      "        POS       0.82      0.94      0.88      5553\n",
      "\n",
      "avg / total       0.76      0.78      0.76      8400\n",
      "\n",
      "0.777023809524\n",
      "0.783\n",
      "0.785\n",
      "0.7505\n",
      "0.7875\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (3.9*e-6) #high score # 최대\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/elice/data/test.input') as fp:\n",
    "    test_in = fp.read()\n",
    "    test_in = test_in.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = ensemble.fit(X, y)\n",
    "model = SGDClassifier(alpha=0.0000005, n_iter=19).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "with open('/elice/data/grading.input') as fp:\n",
    "    test_in = fp.read()\n",
    "    test_in = test_in.splitlines()\n",
    " \n",
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list)\n",
    "X_test = test_vectorizer.fit_transform(test_in[:8400])\n",
    "\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = 'submission.txt'#sys.argv[2] # \n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in test_pred:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train, cross validation\n",
    "\n",
    "n = np.arange(15,25)\n",
    "\n",
    "\n",
    "ite = 5 #  반복\n",
    "score = np.zeros([len(n), ite])\n",
    "\n",
    "\n",
    "for i, val in enumerate(n):\n",
    "    for k in range(ite): \n",
    "        \n",
    "        model = SGDClassifier(alpha=2.9e-6, n_iter=val).fit(X, y)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        score[i][k] = accuracy_score(test_out[:8400], test_pred)\n",
    "        \n",
    "print(score)\n",
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77119048  0.77095238  0.76952381]\n",
      " [ 0.77440476  0.77333333  0.77571429]\n",
      " [ 0.775       0.77297619  0.77583333]]\n",
      "[ 0.77055556  0.77448413  0.77460317]\n"
     ]
    }
   ],
   "source": [
    "#alpha 최적값 찾기\n",
    "alpha = np.arange(0.0000039,0.000004, 0.00000001)\n",
    "alpha = np.arange(0.000001,0.00001,0.000001) ## 3e-6 이 일등\n",
    "alpha = np.arange(2.5e-6,3.5e-6,1e-7) ## 2.9e-6이 일등\n",
    "\n",
    "alpha = [0.000001,0.000002, 0.000003]\n",
    "\n",
    "\n",
    "ite = 3 #  반복\n",
    "score = np.zeros([len(alpha), ite])\n",
    "\n",
    "for i, val in enumerate(alpha):\n",
    "    for k in range(ite): \n",
    "        model = SGDClassifier(alpha=val).fit(X, y)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        score[i][k] = accuracy_score(test_out[:8400], test_pred)\n",
    "        \n",
    "print(score)\n",
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = np.arange(2.5e-6,3.5e-6,1e-7)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=  np.array([[1,1],[2,2],[3,3]])\n",
    "a\n",
    "a.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = np.arange(0.0000039,0.000004, 0.00000001)\n",
    "\n",
    "for i in alpha:\n",
    "    model = SGDClassifier(alpha=i).fit(X, y)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = np.arange(0.0000039,0.000004, 0.00000001)\n",
    "a = (0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001)\n",
    "for i in alpha:\n",
    "    model = SGDClassifier(alpha=i).fit(X, y)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = (0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001)\n",
    "for i in alpha:\n",
    "    model = SGDClassifier(alpha=i).fit(X, y)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(alpha=0.0000039).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (3.9*e-6) #high score # 최대\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (3.9*e-6) #high score # 최대\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (3.5*e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (4*e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (3*e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (7*e-5)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (5*e-5)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (1.e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (1.e-5)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd (1.e-4)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd \n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "\n",
    "#t(koken twit pos) - s\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test out sgd \n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "\n",
    "#t(koken twit pos) - s\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 실패\n",
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "                \n",
    "\n",
    "model = Pipeline([\n",
    "            ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))), \n",
    "            ('mb',   SVC(kernel='linear')),\n",
    "        ])\n",
    "\n",
    "\n",
    "X = train_df.review\n",
    "y = train_df.rating_cat\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 최고기록 0.7730\n",
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "                \n",
    "model = Pipeline([\n",
    "            ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))), \n",
    "            ('mb',   LogisticRegression()),\n",
    "        ])\n",
    "\n",
    "\n",
    "X = train_df.review\n",
    "y = train_df.rating_cat\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 낮음\n",
    "model = Pipeline([\n",
    "            ('vect', TfidfVectorizer()), \n",
    "            ('mb', LogisticRegression(C=10.0)),\n",
    "        ])\n",
    "\n",
    "X = train_df.review\n",
    "y = train_df.rating_cat\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['review_nouns'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['review_nouns'][:10].astype(str).apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['review_nouns'] = train_df['review'].apply(twitter.nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter.nouns('안녕하세요 저는 사람입니다. 사랑합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_file = '/elice/data/grading.input'#sys.argv[1] #'/elice/data/test.input' #\n",
    "input_file = '/elice/data/test.input' \n",
    "output_file = 'submission.txt'#sys.argv[2] # \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(input_file) as fp:\n",
    "    test_in = fp.read()\n",
    "\n",
    "test_in = test_in.splitlines()\n",
    "test_pred = model.predict(test_in[:8400])\n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in test_pred:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')\n",
    "        \n",
    "#t(koken twit pos) - s\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t-l(koken twit pos)\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t-l(c=10))\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t-linear svc\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#t-linear svc (5)\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
