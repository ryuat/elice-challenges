{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<konlpy.tag._twitter.Twitter at 0x102f54630>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Twitter\n",
    "import jpype\n",
    "Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB , GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "pos_tagger = Twitter()\n",
    "# read train data\n",
    "\n",
    "with open('./data/train_data.json') as fp:\n",
    "    json_str = fp.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    \n",
    "# convert to dataframe\n",
    "train_df = pd.DataFrame(json_data)\n",
    "\n",
    "# train data preprocessing\n",
    "train_df['rating_cat'] = train_df['rating'].apply(lambda x: \n",
    "                    'NEG' if 1<= x <=3 \n",
    "                     else \n",
    "                      ('NEU' if 4<=x<=7 \n",
    "                     else 'POS'))\n",
    "\n",
    "\n",
    "\n",
    "input_file = './data/test.input'\n",
    "\n",
    "with open(input_file) as fp:\n",
    "    test_in = fp.read()\n",
    "\n",
    "test_in = test_in.splitlines()\n",
    "\n",
    "\n",
    "with open('./data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit\n",
    "from konlpy.tag import Twitter\n",
    "twitter = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in twitter.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), use_idf=False, smooth_idf=False)\n",
    "\n",
    "\n",
    "y = train_df.rating_cat\n",
    "X = vectorizer.fit_transform(train_df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=30).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = LinearSVC()\n",
    "model2 = LogisticRegression()\n",
    "model3 = SGDClassifier(loss='modified_huber',alpha=0.0000039)\n",
    "ensemble = VotingClassifier(estimators=[('svc1', model1), ('logit', model2), ('svc2', model3)], \n",
    "                            voting='soft', weights=[2, 1, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=0.5)\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "feature_list = vectorizer.get_feature_names()\n",
    "\n",
    "input_file = './data/grading.input'\n",
    "\n",
    "with open(input_file) as fp:\n",
    "    test_in = fp.read()\n",
    "\n",
    "test_in = test_in.splitlines()\n",
    "\n",
    "\n",
    "# joblib.dump(feature_list, 'vocabulary.pkl')\n",
    "\n",
    "# vocabulary = joblib.load('vocabulary.pkl') \n",
    "# vocabulary\n",
    "\n",
    "test_vectorizer =  TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2), vocabulary = feature_list, use_idf=False, smooth_idf=False)\n",
    "X_test = test_vectorizer.fit_transform(test_in[:8400])\n",
    "\n",
    "\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'submission.txt'#sys.argv[2] # \n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in test_pred:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')\n",
    "        \n",
    "#t(koken twit pos) - s\n",
    "#print(classification_report(test_out[:8400],test_pred))\n",
    "#print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66107143  0.66107143]\n",
      " [ 0.66107143  0.66107143]\n",
      " [ 0.66107143  0.66107143]\n",
      " [ 0.65904762  0.65880952]\n",
      " [ 0.63285714  0.63369048]]\n",
      "[ 0.66107143  0.66107143  0.66107143  0.65892857  0.63327381]\n"
     ]
    }
   ],
   "source": [
    "#alpha 최적값 찾기\n",
    "alpha = np.arange(0.0000039,0.000004, 0.00000001)\n",
    "alpha = np.arange(0.000001,0.00001,0.000001) ## 3e-6 이 일등\n",
    "alpha = np.arange(2.5e-6,3.5e-6,1e-7) ## 2.9e-6이 일등\n",
    "alpha = [0.001, 0.0001, 0.00001, 0.000001, 0.0000001]\n",
    "\n",
    "ite = 2 #  반복\n",
    "score = np.zeros([len(alpha), ite])\n",
    "\n",
    "for i, val in enumerate(alpha):\n",
    "    for k in range(ite): \n",
    "        model = SGDClassifier(alpha=val).fit(X, y)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        score[i][k] = accuracy_score(test_out[:8400], test_pred)\n",
    "        \n",
    "print(score)\n",
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77797619  0.77595238  0.7777381   0.77666667  0.7775    ]\n",
      " [ 0.77833333  0.77690476  0.77738095  0.77654762  0.77690476]\n",
      " [ 0.7777381   0.7777381   0.77702381  0.77690476  0.77678571]\n",
      " [ 0.77761905  0.7775      0.7777381   0.77714286  0.77785714]\n",
      " [ 0.7777381   0.7775      0.77833333  0.77702381  0.77797619]\n",
      " [ 0.7772619   0.77833333  0.77642857  0.77678571  0.77642857]\n",
      " [ 0.7772619   0.7772619   0.77678571  0.7772619   0.77702381]\n",
      " [ 0.77738095  0.77809524  0.77785714  0.77654762  0.77797619]\n",
      " [ 0.77738095  0.77785714  0.77761905  0.7775      0.7777381 ]\n",
      " [ 0.77678571  0.77702381  0.77797619  0.7772619   0.77761905]]\n",
      "[ 0.77716667  0.77721429  0.7772381   0.77757143  0.77771429  0.77704762\n",
      "  0.77711905  0.77757143  0.77761905  0.77733333]\n"
     ]
    }
   ],
   "source": [
    "# n_iter 최적\n",
    "\n",
    "n = np.arange(15,25)\n",
    "\n",
    "\n",
    "ite = 5 #  반복\n",
    "score = np.zeros([len(n), ite])\n",
    "\n",
    "\n",
    "for i, val in enumerate(n):\n",
    "    for k in range(ite): \n",
    "        \n",
    "        model = SGDClassifier(alpha=2.9e-6, n_iter=val).fit(X, y)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        score[i][k] = accuracy_score(test_out[:8400], test_pred)\n",
    "        \n",
    "print(score)\n",
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(alpha=2.9e-6, n_iter=19).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.66107143  0.66107143]\n",
      " [ 0.66107143  0.66107143]\n",
      " [ 0.66107143  0.66107143]\n",
      " [ 0.65952381  0.65809524]\n",
      " [ 0.63392857  0.63428571]]\n",
      "[ 0.66107143  0.66107143  0.66107143  0.65880952  0.63410714]\n"
     ]
    }
   ],
   "source": [
    "#alpha 최적값 찾기\n",
    "alpha = np.arange(0.0000039,0.000004, 0.00000001)\n",
    "alpha = np.arange(0.000001,0.00001,0.000001) ## 3e-6 이 일등\n",
    "alpha = np.arange(2.5e-6,3.5e-6,1e-7) ## 2.9e-6이 일등\n",
    "alpha = [0.001, 0.0001, 0.00001, 0.000001, 0.0000001]\n",
    "\n",
    "ite = 2 #  반복\n",
    "score = np.zeros([len(alpha), ite])\n",
    "\n",
    "for i, val in enumerate(alpha):\n",
    "    for k in range(ite): \n",
    "        model = SGDClassifier(alpha=val).fit(X, y)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        score[i][k] = accuracy_score(test_out[:8400], test_pred)\n",
    "        \n",
    "print(score)\n",
    "print(score.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77892857142857141"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.50000000e-06,   2.60000000e-06,   2.70000000e-06,\n",
       "         2.80000000e-06,   2.90000000e-06,   3.00000000e-06,\n",
       "         3.10000000e-06,   3.20000000e-06,   3.30000000e-06,\n",
       "         3.40000000e-06])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = np.arange(2.5e-6,3.5e-6,1e-7)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76916667],\n",
       "       [ 0.77690476],\n",
       "       [ 0.77952381],\n",
       "       [ 0.77642857],\n",
       "       [ 0.77440476],\n",
       "       [ 0.77369048],\n",
       "       [ 0.7702381 ],\n",
       "       [ 0.76988095],\n",
       "       [ 0.7675    ]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=  np.array([[1,1],[2,2],[3,3]])\n",
    "a\n",
    "a.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77654762,  0.77357143],\n",
       "       [ 0.77571429,  0.77452381],\n",
       "       [ 0.77571429,  0.77404762],\n",
       "       [ 0.77595238,  0.77559524],\n",
       "       [ 0.77428571,  0.77535714],\n",
       "       [ 0.77559524,  0.77452381],\n",
       "       [ 0.7752381 ,  0.77464286],\n",
       "       [ 0.77380952,  0.77595238],\n",
       "       [ 0.77511905,  0.77559524],\n",
       "       [ 0.77440476,  0.77380952]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77505952,  0.77511905,  0.77488095,  0.77577381,  0.77482143,\n",
       "        0.77505952,  0.77494048,  0.77488095,  0.77535714,  0.77410714])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775833333333\n",
      "0.775714285714\n",
      "0.774642857143\n",
      "0.774285714286\n",
      "0.77619047619\n",
      "0.776666666667\n",
      "0.774880952381\n",
      "0.775\n",
      "0.774761904762\n",
      "0.772976190476\n"
     ]
    }
   ],
   "source": [
    "alpha = np.arange(0.0000039,0.000004, 0.00000001)\n",
    "\n",
    "for i in alpha:\n",
    "    model = SGDClassifier(alpha=i).fit(X, y)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.775119047619\n",
      "0.776428571429\n",
      "0.774166666667\n",
      "0.775\n",
      "0.775\n",
      "0.775595238095\n",
      "0.775119047619\n",
      "0.775\n",
      "0.77619047619\n",
      "0.775\n"
     ]
    }
   ],
   "source": [
    "alpha = np.arange(0.0000039,0.000004, 0.00000001)\n",
    "a = (0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001)\n",
    "for i in alpha:\n",
    "    model = SGDClassifier(alpha=i).fit(X, y)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = (0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001)\n",
    "for i in alpha:\n",
    "    model = SGDClassifier(alpha=i).fit(X, y)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SGDClassifier(alpha=0.0000039).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.63      0.56      0.59      1022\n",
      "        NEU       0.67      0.39      0.49      1825\n",
      "        POS       0.82      0.94      0.88      5553\n",
      "\n",
      "avg / total       0.76      0.78      0.76      8400\n",
      "\n",
      "0.777857142857\n",
      "0.7855\n",
      "0.7855\n",
      "0.751\n",
      "0.7875\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (3.9*e-6) #high score # 최대\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.64      0.55      0.59      1022\n",
      "        NEU       0.68      0.38      0.48      1825\n",
      "        POS       0.81      0.95      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.78      0.76      8400\n",
      "\n",
      "0.776547619048\n",
      "0.7815\n",
      "0.7845\n",
      "0.747\n",
      "0.790416666667\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (3.9*e-6) #high score # 최대\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.63      0.56      0.59      1022\n",
      "        NEU       0.66      0.39      0.49      1825\n",
      "        POS       0.81      0.94      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.78      0.76      8400\n",
      "\n",
      "0.775238095238\n",
      "0.7835\n",
      "0.7815\n",
      "0.7475\n",
      "0.78625\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (3.5*e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.63      0.55      0.59      1022\n",
      "        NEU       0.67      0.37      0.48      1825\n",
      "        POS       0.81      0.95      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.75      8400\n",
      "\n",
      "0.774285714286\n",
      "0.783\n",
      "0.783\n",
      "0.743\n",
      "0.785833333333\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (4*e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.64      0.56      0.60      1022\n",
      "        NEU       0.66      0.37      0.48      1825\n",
      "        POS       0.81      0.95      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.78      0.75      8400\n",
      "\n",
      "0.775714285714\n",
      "0.7815\n",
      "0.7865\n",
      "0.7455\n",
      "0.787083333333\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (3*e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.65      0.53      0.58      1022\n",
      "        NEU       0.68      0.34      0.46      1825\n",
      "        POS       0.80      0.96      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.75      8400\n",
      "\n",
      "0.77130952381\n",
      "0.7785\n",
      "0.782\n",
      "0.743\n",
      "0.78\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (7*e-5)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.64      0.55      0.59      1022\n",
      "        NEU       0.69      0.35      0.46      1825\n",
      "        POS       0.80      0.95      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.75      8400\n",
      "\n",
      "0.77369047619\n",
      "0.7805\n",
      "0.7825\n",
      "0.745\n",
      "0.784583333333\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (5*e-5)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.55      0.56      0.56      1022\n",
      "        NEU       0.51      0.45      0.48      1825\n",
      "        POS       0.84      0.87      0.85      5553\n",
      "\n",
      "avg / total       0.73      0.74      0.73      8400\n",
      "\n",
      "0.739642857143\n",
      "0.721\n",
      "0.7575\n",
      "0.713\n",
      "0.7625\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (1.e-6)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.62      0.59      0.60      1022\n",
      "        NEU       0.61      0.43      0.50      1825\n",
      "        POS       0.83      0.92      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.76      8400\n",
      "\n",
      "0.773571428571\n",
      "0.776\n",
      "0.779\n",
      "0.743\n",
      "0.7925\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (1.e-5)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.65      0.53      0.58      1022\n",
      "        NEU       0.70      0.31      0.43      1825\n",
      "        POS       0.79      0.96      0.87      5553\n",
      "\n",
      "avg / total       0.75      0.77      0.74      8400\n",
      "\n",
      "0.765595238095\n",
      "0.77\n",
      "0.7775\n",
      "0.7325\n",
      "0.779583333333\n"
     ]
    }
   ],
   "source": [
    "# test out sgd (1.e-4)\n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "#sgd()\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n",
    "\n",
    "print(accuracy_score(test_out[6400:8400], test_pred[6400:8400]))\n",
    "print(accuracy_score(test_out[4400:6400], test_pred[4400:6400]))\n",
    "print(accuracy_score(test_out[2400:4400], test_pred[2400:4400]))\n",
    "print(accuracy_score(test_out[:2400], test_pred[:2400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.86      0.05      0.10      1022\n",
      "        NEU       0.60      0.00      0.01      1825\n",
      "        POS       0.67      1.00      0.80      5553\n",
      "\n",
      "avg / total       0.68      0.67      0.54      8400\n",
      "\n",
      "0.667976190476\n"
     ]
    }
   ],
   "source": [
    "# test out sgd \n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "\n",
    "#t(koken twit pos) - s\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.70      0.27      0.39      1022\n",
      "        NEU       0.71      0.09      0.16      1825\n",
      "        POS       0.71      0.99      0.82      5553\n",
      "\n",
      "avg / total       0.71      0.71      0.63      8400\n",
      "\n",
      "0.705595238095\n"
     ]
    }
   ],
   "source": [
    "# test out sgd \n",
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()\n",
    "\n",
    "\n",
    "#t(koken twit pos) - s\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 실패\n",
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "                \n",
    "\n",
    "model = Pipeline([\n",
    "            ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))), \n",
    "            ('mb',   SVC(kernel='linear')),\n",
    "        ])\n",
    "\n",
    "\n",
    "X = train_df.review\n",
    "y = train_df.rating_cat\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 최고기록 0.7730\n",
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize_pos(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]\n",
    "\n",
    "                \n",
    "model = Pipeline([\n",
    "            ('vect', TfidfVectorizer(tokenizer=tokenize_pos, ngram_range=(1,2))), \n",
    "            ('mb',   LogisticRegression()),\n",
    "        ])\n",
    "\n",
    "\n",
    "X = train_df.review\n",
    "y = train_df.rating_cat\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "  ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 낮음\n",
    "model = Pipeline([\n",
    "            ('vect', TfidfVectorizer()), \n",
    "            ('mb', LogisticRegression(C=10.0)),\n",
    "        ])\n",
    "\n",
    "X = train_df.review\n",
    "y = train_df.rating_cat\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    ['종합', '평점', '점']\n",
       "1    ['원작', '칭송', '이유', '웹툰', '계', '자체', '질적', '저하'...\n",
       "2    ['나름', '감동', '마음', '가슴', '배우', '연기', '김수현', '최고']\n",
       "3    ['걸', '돈', '자신', '후회', '최악', '쓰레기', '영화', '김수현...\n",
       "4               ['초반', '코미디', '후반', '액션', '결론', '코미디']\n",
       "5                       ['김수현', '일', '처리', '처리', '절차']\n",
       "6                                    ['원작', '어디', '팔']\n",
       "7                        ['나름', '장면', '해도', '나름', '볼']\n",
       "8                                ['님', '이영화', '클레멘타인']\n",
       "9                    ['좀', '억지', '감동', '좀', '유치', '함']\n",
       "Name: review_nouns, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['review_nouns'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [ ' 종 합 ' ,   ' 평 점 ' ,   ' 점 ' ]\n",
       "1    [ ' 원 작 ' ,   ' 칭 송 ' ,   ' 이 유 ' ,   ' 웹 툰 ' ...\n",
       "2    [ ' 나 름 ' ,   ' 감 동 ' ,   ' 마 음 ' ,   ' 가 슴 ' ...\n",
       "3    [ ' 걸 ' ,   ' 돈 ' ,   ' 자 신 ' ,   ' 후 회 ' ,   ...\n",
       "4    [ ' 초 반 ' ,   ' 코 미 디 ' ,   ' 후 반 ' ,   ' 액 션 ...\n",
       "5    [ ' 김 수 현 ' ,   ' 일 ' ,   ' 처 리 ' ,   ' 처 리 ' ...\n",
       "6                    [ ' 원 작 ' ,   ' 어 디 ' ,   ' 팔 ' ]\n",
       "7    [ ' 나 름 ' ,   ' 장 면 ' ,   ' 해 도 ' ,   ' 나 름 ' ...\n",
       "8            [ ' 님 ' ,   ' 이 영 화 ' ,   ' 클 레 멘 타 인 ' ]\n",
       "9    [ ' 좀 ' ,   ' 억 지 ' ,   ' 감 동 ' ,   ' 좀 ' ,   ...\n",
       "Name: review_nouns, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['review_nouns'][:10].astype(str).apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import *\n",
    "twitter = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['review_nouns'] = train_df['review'].apply(twitter.nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-24f97c1ce3be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_df.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df.to_csv('train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['저', '사람']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter.nouns('안녕하세요 저는 사람입니다. 사랑합니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 8400 features per sample; expecting 1862890",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-bc4235b1dd7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \"\"\"\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0;32m--> 317\u001b[0;31m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[0;31mValueError\u001b[0m: X has 8400 features per sample; expecting 1862890"
     ]
    }
   ],
   "source": [
    "#input_file = '/elice/data/grading.input'#sys.argv[1] #'/elice/data/test.input' #\n",
    "input_file = '/elice/data/test.input' \n",
    "output_file = 'submission.txt'#sys.argv[2] # \n",
    "\n",
    "\n",
    "\n",
    "with open(input_file) as fp:\n",
    "    test_in = fp.read()\n",
    "\n",
    "test_in = test_in.splitlines()\n",
    "test_pred = model.predict(test_in[:8400])\n",
    "\n",
    "\n",
    "with open(output_file, 'w') as fp:\n",
    "    for _test_pred in test_pred:\n",
    "        fp.write(_test_pred)\n",
    "        fp.write('\\n')\n",
    "        \n",
    "#t(koken twit pos) - s\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Twitter\n",
    "pos_tagger = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/elice/data/test.output') as fp:\n",
    "    test_out = fp.read()\n",
    "    test_out = test_out.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.64      0.53      0.58      1022\n",
      "        NEU       0.62      0.42      0.50      1825\n",
      "        POS       0.82      0.93      0.87      5553\n",
      "\n",
      "avg / total       0.76      0.77      0.76      8400\n",
      "\n",
      "0.773095238095\n"
     ]
    }
   ],
   "source": [
    "#t-l(koken twit pos)\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.60      0.48      0.53      1022\n",
      "        NEU       0.55      0.41      0.47      1825\n",
      "        POS       0.81      0.91      0.85      5553\n",
      "\n",
      "avg / total       0.73      0.75      0.73      8400\n",
      "\n",
      "0.74630952381\n"
     ]
    }
   ],
   "source": [
    "#t-l(c=10))\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.61      0.58      0.60      1022\n",
      "        NEU       0.58      0.44      0.50      1825\n",
      "        POS       0.84      0.91      0.87      5553\n",
      "\n",
      "avg / total       0.75      0.77      0.76      8400\n",
      "\n",
      "0.768333333333\n"
     ]
    }
   ],
   "source": [
    "#t-linear svc\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        NEG       0.57      0.57      0.57      1022\n",
      "        NEU       0.52      0.44      0.48      1825\n",
      "        POS       0.84      0.88      0.86      5553\n",
      "\n",
      "avg / total       0.74      0.75      0.74      8400\n",
      "\n",
      "0.74619047619\n"
     ]
    }
   ],
   "source": [
    "#t-linear svc (5)\n",
    "print(classification_report(test_out[:8400],test_pred))\n",
    "print(accuracy_score(test_out[:8400], test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4391"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
